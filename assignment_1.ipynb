{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     C:\\Users\\viggo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pip install nltk\n",
    "import nltk\n",
    "import string\n",
    "nltk.download('gutenberg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Challenge 1: build your own concordance\n",
    "\n",
    "Pick a different book and a different word, or pair of words. Copy and paste from the code above to write some Python code that searches the book of your choice for the word or pair of words of your choice. Put this code in the cell below. By the way, some of the texts use the characters \"\\r\" for \"carriage return\" instead of \"\\n\" for \"newline\". You can remove these the same way that you remove the \"\\n\" characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "moby_dick = nltk.corpus.gutenberg.raw('melville-moby_dick.txt')\n",
    "\n",
    "# make all characters lowercase\n",
    "moby_dick = moby_dick.lower()\n",
    "\n",
    "# remove the \"\\n\" characters, which indicate line breaks in the text (newlines)\n",
    "moby_dick = moby_dick.replace('\\r', ' ')\n",
    "moby_dick = moby_dick.replace('\\n', ' ')\n",
    "\n",
    "moby_dick = moby_dick.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "# split up the text into a long list of individual words\n",
    "moby_dick = moby_dick.split()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "concordance = []\n",
    "for i, val in enumerate(moby_dick):\n",
    "    if val == \"ishmael\":\n",
    "        start = max(i-5, 0)  # Ensure start doesn't go below 0\n",
    "        end = min(i+5, len(moby_dick))  # Ensure end doesn't exceed list length\n",
    "        concordance.append(' '.join(moby_dick[start:end]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chapter 1 loomings call me ishmael some years agonever mind',\n",
       " 'states whaling voyage by one ishmael bloody battle in affghanistan',\n",
       " 'of silverso wherever you go ishmael said i to myself',\n",
       " 'for the night my dear ishmael be sure to inquire',\n",
       " 'glasses within but go on ishmael said i at last',\n",
       " 'wailing and teethgnashing there ha ishmael muttered i backing out',\n",
       " 'had gone before me yes ishmael the same fate may',\n",
       " 'i do you suppose now ishmael that the magnanimous god',\n",
       " 'if left to myself i ishmael should infallibly light upon',\n",
       " 'then down ye go here ishmael for the three hundredth',\n",
       " 'chapter 41 moby dick i ishmael was one of that',\n",
       " 'be to dive deeper than ishmael can go the subterranean',\n",
       " 'thou surrenderest to a hypo ishmael tell me why this',\n",
       " 'of prairies all these to ishmael are as the shaking',\n",
       " 'subtle meanings how may unlettered ishmael hope to read the',\n",
       " 'unconditional skeleton but how now ishmael how is it that',\n",
       " 'rib for exhibition explain thyself ishmael can you land a',\n",
       " 'witness have you hitherto been ishmael but have a care']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concordance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(concordance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 2: compare lengths of books\n",
    "\n",
    "We can use the command `len` to find how many items there are in a list. E.g., to find the number of words in the list called `bible`, above, we can write: `len(bible)`. \n",
    "\n",
    "Use the starter code below to find out which book in the books included in `nltk` has the most words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: blake-poems.txt, Word Count: 6819\n",
      "Title: burgess-busterbrown.txt, Word Count: 15870\n",
      "Title: shakespeare-macbeth.txt, Word Count: 17722\n",
      "Title: shakespeare-caesar.txt, Word Count: 20451\n",
      "Title: carroll-alice.txt, Word Count: 26383\n",
      "Title: shakespeare-hamlet.txt, Word Count: 29579\n",
      "Title: bryant-stories.txt, Word Count: 45973\n",
      "Title: chesterton-thursday.txt, Word Count: 57915\n",
      "Title: chesterton-brown.txt, Word Count: 71626\n",
      "Title: milton-paradise.txt, Word Count: 79649\n",
      "Title: chesterton-ball.txt, Word Count: 81576\n",
      "Title: austen-persuasion.txt, Word Count: 83303\n",
      "Title: austen-sense.txt, Word Count: 118673\n",
      "Title: whitman-leaves.txt, Word Count: 121688\n",
      "Title: austen-emma.txt, Word Count: 158131\n",
      "Title: edgeworth-parents.txt, Word Count: 166012\n",
      "Title: melville-moby_dick.txt, Word Count: 212013\n",
      "Title: bible-kjv.txt, Word Count: 821131\n"
     ]
    }
   ],
   "source": [
    "books = nltk.corpus.gutenberg.fileids()\n",
    "cleaned_books = []\n",
    "\n",
    "for title in books:\n",
    "    book = nltk.corpus.gutenberg.raw(title)\n",
    "    book_cleaned = book.lower().replace('\\n', ' ').replace('\\r', ' ').translate(str.maketrans('', '', string.punctuation)).split()\n",
    "    cleaned_books.append((title, book_cleaned, len(book_cleaned)))\n",
    "\n",
    "cleaned_books_sorted = sorted(cleaned_books, key=lambda x: x[2])\n",
    "\n",
    "for title, _, word_count in cleaned_books_sorted:\n",
    "    print(f'Title: {title}, Word Count: {word_count}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_book(title):\n",
    "    for book_title, cleaned_text, _ in cleaned_books_sorted:\n",
    "        if book_title == title:\n",
    "            return cleaned_text\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 3: what are the most frequent words?\n",
    "\n",
    "`nltk` has a built-in function called `FreqDist` which counts up how many times each word in a text occurs. So, if you have a list called `words` which contains all the words in a book, you can find the frequencies of all of them by writing `freq = nltk.FreqDist(words)`. You can then get the e.g. ten most common words by writing `freq.most_common(10)`. What are the ten most common words in Jane Austen's \"Emma\"? What about Herman Melville's \"Moby Dick\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('to', 5149),\n",
       " ('the', 5146),\n",
       " ('and', 4613),\n",
       " ('of', 4274),\n",
       " ('a', 3073),\n",
       " ('i', 2968),\n",
       " ('her', 2417),\n",
       " ('it', 2400),\n",
       " ('was', 2376),\n",
       " ('she', 2278)]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# starter code:\n",
    "emma = get_book('austen-emma.txt')\n",
    "freq_emma = nltk.FreqDist(emma)\n",
    "freq_emma.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 14320),\n",
       " ('of', 6578),\n",
       " ('and', 6362),\n",
       " ('a', 4628),\n",
       " ('to', 4577),\n",
       " ('in', 4143),\n",
       " ('that', 2940),\n",
       " ('his', 2520),\n",
       " ('it', 2368),\n",
       " ('i', 1943)]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moby_dick = get_book('melville-moby_dick.txt')\n",
    "freq_moby_dick = nltk.FreqDist(moby_dick)\n",
    "freq_moby_dick.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 4: Remove stopwords\n",
    "\n",
    "Often, the most frequent words are not the most interesting ones. Words like \"a\" and \"the\" are so common in English, that they don't really tell us much about the text. That is why we often remove \"stopwords\", that is, a list of the most common words in English, before e.g. counting frequencies. There are several of these lists available, in [English]((https://gist.github.com/sebleier/554280)) as well as other languages, such as [Danish](https://gist.github.com/berteltorp/0cf8a0c7afea7f25ed754f24cfc2467b). Below is some starter code to remove stopwords. Use these snippets to see what the most common words in Emma and Moby Dick are after removing these most common words.\n",
    "\n",
    "Hint: In Moby Dick, you will also have to remove the string `\\r`, in addition to removing `\\n`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of stopwords\n",
    "\n",
    "stopwords = [\"\", \"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mr', 1124),\n",
       " ('could', 830),\n",
       " ('would', 817),\n",
       " ('emma', 751),\n",
       " ('mrs', 687),\n",
       " ('miss', 587),\n",
       " ('must', 567),\n",
       " ('much', 474),\n",
       " ('said', 474),\n",
       " ('one', 428)]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emma = get_book('austen-emma.txt')\n",
    "emma = [word for word in emma if word not in stopwords]\n",
    "freq_emma = nltk.FreqDist(emma)\n",
    "freq_emma.most_common(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('whale', 954),\n",
       " ('one', 889),\n",
       " ('like', 575),\n",
       " ('upon', 565),\n",
       " ('old', 440),\n",
       " ('man', 435),\n",
       " ('would', 427),\n",
       " ('ye', 421),\n",
       " ('ahab', 417),\n",
       " ('whales', 389)]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moby_dick = get_book('melville-moby_dick.txt')\n",
    "moby_dick = [word for word in moby_dick if word not in stopwords]\n",
    "freq_moby_dick = nltk.FreqDist(moby_dick)\n",
    "freq_moby_dick.most_common(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
